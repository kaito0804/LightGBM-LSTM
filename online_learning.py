# online_learning.py (ä¿®æ­£ç‰ˆ)
"""
ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  (ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ  & æ–°ç‰¹å¾´é‡å¯¾å¿œç‰ˆ)
- åˆ†é¡ãƒ¢ãƒ‡ãƒ«(æ–¹å‘)ã¨å›å¸°ãƒ¢ãƒ‡ãƒ«(å€¤å¹…)ã®ä¸¡æ–¹ã‚’å®‰å…¨ã«æ›´æ–°
- æœŸå¾…å€¤ãƒ­ã‚¸ãƒƒã‚¯ã®é®®åº¦ã‚’ç¶­æŒã™ã‚‹
- 15m/1h ä¸¡å¯¾å¿œ
"""

import pandas as pd
import os
import threading
import time
import numpy as np
from datetime import datetime
from ml_predictor import MLPredictor
from data_collector import DataCollector
import lightgbm as lgb
from sklearn.metrics import mean_squared_error

class OnlineLearner:
    def __init__(self, symbol='ETH', timeframe='15m', retrain_interval_hours=24):
        self.symbol = symbol
        self.timeframe = timeframe 
        self.retrain_interval = retrain_interval_hours * 3600
        
        # ãƒ‡ãƒ¼ã‚¿åé›†å™¨
        self.collector = DataCollector(symbol)
        
        # â˜…ä¿®æ­£1: MLPredictorã«timeframeã‚’æ¸¡ã™
        self.predictor = MLPredictor(symbol, timeframe=timeframe)
        
        self.training_data_path = f"training_data/{symbol}_{timeframe}_training.csv"
        self.last_retrain_time = time.time()
        self.max_rows = 40000
        
        self.learning_thread = None
        self.is_running = False
        
        print(f"ğŸ”„ ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’åˆæœŸåŒ–: {timeframe}è¶³ (é–“éš”: {retrain_interval_hours}h)")
    
    def _calculate_features_online(self, df):
        """
        ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ç”¨ã«ç‰¹å¾´é‡ã‚’è¨ˆç®—ã™ã‚‹
        (fetch_binance_data.py ã®ãƒ­ã‚¸ãƒƒã‚¯ã¨æ•´åˆæ€§ã‚’å–ã‚‹)
        â€»BTCãƒ‡ãƒ¼ã‚¿ã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å–å¾—ãŒé›£ã—ã„ãŸã‚ã€ç›¸é–¢ç³»ã¯0åŸ‹ã‚ã¾ãŸã¯æ—¢å­˜å€¤ã‚’ç¶­æŒ
        """
        df = df.copy()
        close = df['close']
        high = df['high']
        low = df['low']
        volume = df['volume']
        
        # --- åŸºæœ¬æŒ‡æ¨™ ---
        # RSI
        delta = close.diff()
        gain = (delta.where(delta > 0, 0)).ewm(alpha=1/14, min_periods=14, adjust=False).mean()
        loss = (-delta.where(delta < 0, 0)).ewm(alpha=1/14, min_periods=14, adjust=False).mean()
        rs = gain / loss.replace(0, np.nan)
        df['rsi'] = 100 - (100 / (1 + rs))
        df['rsi'] = df['rsi'].fillna(50)
        
        # MACD
        ema12 = close.ewm(span=12, adjust=False).mean()
        ema26 = close.ewm(span=26, adjust=False).mean()
        macd = ema12 - ema26
        signal = macd.ewm(span=9, adjust=False).mean()
        df['macd_hist'] = macd - signal
        
        # BB
        sma20 = close.rolling(20).mean()
        std20 = close.rolling(20).std(ddof=0)
        df['bb_position'] = (close - (sma20 - 2*std20)) / (4*std20)
        df['bb_width'] = (4*std20) / sma20
        
        # ATR
        tr1 = high - low
        tr2 = (high - close.shift()).abs()
        tr3 = (low - close.shift()).abs()
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        df['atr'] = tr.ewm(alpha=1/14, min_periods=14, adjust=False).mean()
        
        # SMA & Volume
        df['sma_20'] = sma20
        df['sma_50'] = close.rolling(50).mean()
        df['sma_20_50_ratio'] = (df['sma_20'] / df['sma_50'] - 1) * 100
        
        vol_ma = volume.rolling(20).mean()
        df['volume_ratio'] = volume / vol_ma.replace(0, 1)
        
        # --- â˜…ä¿®æ­£2: æ–°æ©Ÿèƒ½ã®ç‰¹å¾´é‡ã‚’è¿½åŠ  ---
        current_return = close.pct_change(1).fillna(0) * 100
        df['price_change_1h'] = current_return
        df['price_change_4h'] = close.pct_change(4).fillna(0) * 100
        
        df['return_lag_1'] = current_return.shift(1).fillna(0)
        df['return_lag_2'] = current_return.shift(2).fillna(0)
        df['return_lag_3'] = current_return.shift(3).fillna(0)
        
        long_term_atr = df['atr'].rolling(10).mean().replace(0, 1)
        df['volatility_ratio'] = df['atr'] / long_term_atr
        df['volatility'] = close.rolling(20).std() / sma20 * 100
        
        # æ™‚é–“ç‰¹å¾´é‡
        if 'timestamp' in df.columns:
            # timestampãŒdatetimeå‹ã§ãªã„å ´åˆã¯å¤‰æ›
            if not pd.api.types.is_datetime64_any_dtype(df['timestamp']):
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                
            df['hour_sin'] = np.sin(2 * np.pi * df['timestamp'].dt.hour / 24)
            df['hour_cos'] = np.cos(2 * np.pi * df['timestamp'].dt.hour / 24)
            df['day_of_week'] = df['timestamp'].dt.dayofweek / 6.0
        
        # ä¸è¶³ã—ã¦ã„ã‚‹ã‚«ãƒ©ãƒ (BTCç³»ãªã©)ã¯0ã§åŸ‹ã‚ã‚‹
        for col in self.predictor.feature_cols:
            if col not in df.columns:
                df[col] = 0.0
                
        # --- ãƒ©ãƒ™ãƒ«ä½œæˆ (æ­£è§£ãƒ‡ãƒ¼ã‚¿) ---
        horizon = 1
        future_change = close.shift(-horizon).pct_change(1) * 100
        df['future_change'] = (df['close'].shift(-horizon) - df['close']) / df['close'] * 100
        
        atr_pct = (df['atr'] / close) * 100
        threshold = (atr_pct * 0.20).clip(0.08, 1.2)
        
        conditions = [
            (df['future_change'] > threshold),
            (df['future_change'] < -threshold)
        ]
        choices = [1, -1] # Buy, Sell
        df['label'] = np.select(conditions, choices, default=0)
        
        return df.dropna()

    def collect_latest_data(self, lookback_limit=500):
        """æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¦ç‰¹å¾´é‡ã‚’è¨ˆç®—ã—ã€CSVã«è¿½è¨˜"""
        # 1. ç”Ÿãƒ‡ãƒ¼ã‚¿ã®åé›†
        raw_df = self.collector.collect_historical_data(timeframe=self.timeframe, limit=lookback_limit)
        
        if raw_df is None or raw_df.empty:
            return None

        # â˜…ä¿®æ­£3: ä¿å­˜å‰ã«ç‰¹å¾´é‡è¨ˆç®—ã‚’è¡Œã† (ã“ã‚ŒãŒãªã„ã¨csvãŒå£Šã‚Œã‚‹)
        new_df = self._calculate_features_online(raw_df)

        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨ã®çµåˆ
        if os.path.exists(self.training_data_path):
            try:
                existing_df = pd.read_csv(self.training_data_path)
                # timestampã®å‹åˆã‚ã›
                if 'timestamp' in existing_df.columns:
                    existing_df['timestamp'] = pd.to_datetime(existing_df['timestamp'])
                
                combined_df = pd.concat([existing_df, new_df], ignore_index=True)
                if 'timestamp' in combined_df.columns:
                    combined_df = combined_df.drop_duplicates(subset=['timestamp'], keep='last')
                    combined_df = combined_df.sort_values('timestamp').reset_index(drop=True)
            except Exception as e:
                print(f"âš ï¸ CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼(æ–°è¦ä½œæˆã—ã¾ã™): {e}")
                combined_df = new_df
        else:
            combined_df = new_df

        # ã‚µã‚¤ã‚ºåˆ¶é™
        if len(combined_df) > self.max_rows:
            combined_df = combined_df.tail(self.max_rows)

        # ä¿å­˜
        os.makedirs(os.path.dirname(self.training_data_path), exist_ok=True)
        combined_df.to_csv(self.training_data_path, index=False)
        
        return combined_df
    
    def retrain_models(self):
        """å®‰å…¨è£…ç½®ä»˜ãå†å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹"""
        # 1. æœ€æ–°ãƒ‡ãƒ¼ã‚¿åé›† (ç‰¹å¾´é‡è¨ˆç®—è¾¼ã¿)
        df = self.collect_latest_data(lookback_limit=300)
        if df is None or len(df) < 500:
            print("âš ï¸ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
            return

        print(f"ğŸ”„ å®‰å…¨å†å­¦ç¿’é–‹å§‹ ({self.timeframe}): {len(df)} lines")
        
        # 2. ç›´è¿‘ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼ç”¨(Validation)ã«å–ã‚Šåˆ†ã‘ã‚‹
        split_idx = int(len(df) * 0.85)
        train_df = df.iloc[:split_idx]
        val_df = df.iloc[split_idx:]
        
        feature_cols = self.predictor.feature_cols
        
        # ç‰¹å¾´é‡ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        for c in feature_cols:
            if c not in train_df.columns: train_df[c] = 0.0
            if c not in val_df.columns: val_df[c] = 0.0

        X_train = train_df[feature_cols]
        X_val = val_df[feature_cols]
        
        # ==========================================
        # 1. åˆ†é¡ãƒ¢ãƒ‡ãƒ« (LightGBM Classifier) ã®æ›´æ–°
        # ==========================================
        print("ğŸ“Š [1/3] åˆ†é¡ãƒ¢ãƒ‡ãƒ«(æ–¹å‘)ã®æ›´æ–°ãƒã‚§ãƒƒã‚¯")
        y_cls_train = train_df['label']
        y_cls_val = val_df['label']
        
        # ç¾åœ¨ã®ç²¾åº¦ç¢ºèª
        current_acc = 0.0
        with self.predictor.model_lock:
            if self.predictor.lgb_model:
                current_acc = self.predictor.evaluate_model(self.predictor.lgb_model, X_val, y_cls_val, 'lgb')
        
        # æ–°è¦å­¦ç¿’
        y_train_mapped = y_cls_train.map({-1:0, 0:1, 1:2})
        params_cls = {
            'objective': 'multiclass', 'num_class': 3, 'verbose': -1, 
            'random_state': 42, 'learning_rate': 0.05
        }
        train_set_cls = lgb.Dataset(X_train, label=y_train_mapped)
        new_lgb_cls = lgb.train(params_cls, train_set_cls, num_boost_round=100)
        
        new_acc = self.predictor.evaluate_model(new_lgb_cls, X_val, y_cls_val, 'lgb')
        
        if new_acc >= current_acc - 0.03:
            print(f"   âœ… æ›´æ–°æ‰¿èª (Acc: {current_acc:.3f} -> {new_acc:.3f})")
            with self.predictor.model_lock:
                self.predictor.lgb_model = new_lgb_cls
                try:
                    import joblib
                    joblib.dump(new_lgb_cls, self.predictor.lgb_path)
                except: pass
        else:
            print(f"   ğŸ›‘ æ›´æ–°å´ä¸‹ (ç²¾åº¦ä½ä¸‹: {current_acc:.3f} -> {new_acc:.3f})")

        # ==========================================
        # 2. å›å¸°ãƒ¢ãƒ‡ãƒ« (LightGBM Regressor) ã®æ›´æ–°
        # ==========================================
        print("ğŸ“Š [2/3] å›å¸°ãƒ¢ãƒ‡ãƒ«(å€¤å¹…)ã®æ›´æ–°ãƒã‚§ãƒƒã‚¯")
        if 'future_change' in train_df.columns:
            y_reg_train = train_df['future_change']
            y_reg_val = val_df['future_change']
            
            # ç¾åœ¨ã®èª¤å·®(RMSE)ç¢ºèª
            current_rmse = 999.0
            with self.predictor.model_lock:
                if self.predictor.lgb_reg_model:
                    try:
                        preds = self.predictor.lgb_reg_model.predict(X_val)
                        current_rmse = np.sqrt(mean_squared_error(y_reg_val, preds))
                    except: pass
            
            # æ–°è¦å­¦ç¿’
            params_reg = {
                'objective': 'regression', 'metric': 'rmse', 'verbose': -1, 
                'random_state': 42, 'learning_rate': 0.05
            }
            train_set_reg = lgb.Dataset(X_train, label=y_reg_train)
            new_lgb_reg = lgb.train(params_reg, train_set_reg, num_boost_round=100)
            
            # æ–°è¦RMSEç¢ºèª
            new_preds = new_lgb_reg.predict(X_val)
            new_rmse = np.sqrt(mean_squared_error(y_reg_val, new_preds))
            
            # RMSEã¯ä½ã„æ–¹ãŒè‰¯ã„ (å¤šå°‘ã®æ‚ªåŒ–ã¯è¨±å®¹ã—ã¦æœ€æ–°ãƒˆãƒ¬ãƒ³ãƒ‰ã«è¿½å¾“ã•ã›ã‚‹)
            if new_rmse <= current_rmse * 1.1: 
                print(f"   âœ… æ›´æ–°æ‰¿èª (RMSE: {current_rmse:.4f} -> {new_rmse:.4f})")
                with self.predictor.model_lock:
                    self.predictor.lgb_reg_model = new_lgb_reg
                    try:
                        import joblib
                        joblib.dump(new_lgb_reg, self.predictor.lgb_reg_path)
                    except: pass
            else:
                print(f"   ğŸ›‘ æ›´æ–°å´ä¸‹ (èª¤å·®å¢—å¤§: {current_rmse:.4f} -> {new_rmse:.4f})")
        else:
            print("   âš ï¸ future_changeåˆ—ãŒãªã„ãŸã‚å›å¸°ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¹ã‚­ãƒƒãƒ—")

        # ==========================================
        # 3. LSTM å†å­¦ç¿’
        # ==========================================
        print("ğŸ§  [3/3] LSTMå†å­¦ç¿’ä¸­...")
        if 'close' in df.columns:
            prices = df['close'].values
            labels = df['label'].values
            self.predictor.train_lstm(prices, labels)

        self.last_retrain_time = time.time()
        print(f"âœ¨ å…¨ãƒ¢ãƒ‡ãƒ«æ›´æ–°ãƒ—ãƒ­ã‚»ã‚¹å®Œäº†")

    def start_background_learning(self):
        if self.is_running: return
        self.is_running = True
        self.learning_thread = threading.Thread(target=self._learning_loop, daemon=True)
        self.learning_thread.start()
        print(f"âœ… ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å­¦ç¿’é–‹å§‹")
    
    def _learning_loop(self):
        while self.is_running:
            elapsed = time.time() - self.last_retrain_time
            remaining = self.retrain_interval - elapsed
            
            if remaining <= 0:
                try:
                    self.retrain_models()
                except Exception as e:
                    print(f"âŒ å†å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
            
            sleep_time = min(3600, max(60, remaining))
            time.sleep(sleep_time)

    def stop_background_learning(self):
        self.is_running = False
        if self.learning_thread:
            self.learning_thread.join(timeout=5)