"""
ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  (ãƒ‡ã‚¤ãƒˆãƒ¬ãƒ¼ãƒ‰æœ€é©åŒ–ç‰ˆãƒ»ä¿®æ­£ç‰ˆ)
- åˆ†é¡ãƒ¢ãƒ‡ãƒ«(æ–¹å‘)ã¨å›å¸°ãƒ¢ãƒ‡ãƒ«(å€¤å¹…)ã®ä¸¡æ–¹ã‚’å®‰å…¨ã«æ›´æ–°
- æœŸå¾…å€¤ãƒ­ã‚¸ãƒƒã‚¯ã®é®®åº¦ã‚’ç¶­æŒã™ã‚‹
"""

import pandas as pd
import os
import threading
import time
import numpy as np
from datetime import datetime
from ml_predictor import MLPredictor
from data_collector import DataCollector
import lightgbm as lgb
from sklearn.metrics import mean_squared_error

class OnlineLearner:
    def __init__(self, symbol='ETH', timeframe='15m', retrain_interval_hours=24):
        self.symbol = symbol
        self.timeframe = timeframe 
        self.retrain_interval = retrain_interval_hours * 3600
        
        self.collector = DataCollector(symbol)
        self.predictor = MLPredictor(symbol)
        
        self.training_data_path = f"training_data/{symbol}_{timeframe}_training.csv"
        self.last_retrain_time = time.time()
        self.max_rows = 40000
        
        self.learning_thread = None
        self.is_running = False
        
        print(f"ğŸ”„ ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’åˆæœŸåŒ–: {timeframe}è¶³ (é–“éš”: {retrain_interval_hours}h)")
    
    def collect_latest_data(self, lookback_limit=500):
        """æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¦CSVã«è¿½è¨˜"""
        new_df = self.collector.collect_historical_data(timeframe=self.timeframe, limit=lookback_limit)
        
        if new_df is None or new_df.empty:
            return None

        if os.path.exists(self.training_data_path):
            try:
                existing_df = pd.read_csv(self.training_data_path)
                combined_df = pd.concat([existing_df, new_df], ignore_index=True)
                if 'timestamp' in combined_df.columns:
                    combined_df = combined_df.drop_duplicates(subset=['timestamp'], keep='last')
                    combined_df = combined_df.sort_values('timestamp').reset_index(drop=True)
            except:
                combined_df = new_df
        else:
            combined_df = new_df

        if len(combined_df) > self.max_rows:
            combined_df = combined_df.tail(self.max_rows)

        os.makedirs(os.path.dirname(self.training_data_path), exist_ok=True)
        combined_df.to_csv(self.training_data_path, index=False)
        
        return combined_df
    
    def retrain_models(self):
        """å®‰å…¨è£…ç½®ä»˜ãå†å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ (åˆ†é¡ & å›å¸°)"""
        # 1. æœ€æ–°ãƒ‡ãƒ¼ã‚¿åé›†
        df = self.collect_latest_data(lookback_limit=300)
        if df is None or len(df) < 500:
            print("âš ï¸ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
            return

        print(f"ğŸ”„ å®‰å…¨å†å­¦ç¿’é–‹å§‹: {len(df)} lines")
        
        # 2. ç›´è¿‘ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼ç”¨(Validation)ã«å–ã‚Šåˆ†ã‘ã‚‹
        split_idx = int(len(df) * 0.85)
        train_df = df.iloc[:split_idx]
        val_df = df.iloc[split_idx:]
        
        feature_cols = self.predictor.feature_cols
        
        # ç‰¹å¾´é‡ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ & æ¬ æåŸ‹ã‚
        # (é‡è¦: data_collector.pyãŒä¿®æ­£ã•ã‚Œã¦ã„ãªã„ã¨ã“ã“ã§0åŸ‹ã‚ã«ãªã‚Šæ€§èƒ½ãŒè½ã¡ã‚‹)
        for c in feature_cols:
            if c not in train_df.columns: train_df[c] = 0.0
            if c not in val_df.columns: val_df[c] = 0.0

        X_train = train_df[feature_cols]
        X_val = val_df[feature_cols]
        
        # ==========================================
        # 1. åˆ†é¡ãƒ¢ãƒ‡ãƒ« (LightGBM Classifier) ã®æ›´æ–°
        # ==========================================
        print("ğŸ“Š [1/3] åˆ†é¡ãƒ¢ãƒ‡ãƒ«(æ–¹å‘)ã®æ›´æ–°ãƒã‚§ãƒƒã‚¯")
        y_cls_train = train_df['label']
        y_cls_val = val_df['label']
        
        # ç¾åœ¨ã®ç²¾åº¦ç¢ºèª
        current_acc = 0.0
        with self.predictor.model_lock:
            if self.predictor.lgb_model:
                current_acc = self.predictor.evaluate_model(self.predictor.lgb_model, X_val, y_cls_val, 'lgb')
        
        # æ–°è¦å­¦ç¿’
        y_train_mapped = y_cls_train.map({-1:0, 0:1, 1:2})
        params_cls = {
            'objective': 'multiclass', 'num_class': 3, 'verbose': -1, 
            'random_state': 42, 'learning_rate': 0.05
        }
        train_set_cls = lgb.Dataset(X_train, label=y_train_mapped)
        new_lgb_cls = lgb.train(params_cls, train_set_cls, num_boost_round=100)
        
        new_acc = self.predictor.evaluate_model(new_lgb_cls, X_val, y_cls_val, 'lgb')
        
        if new_acc >= current_acc - 0.03:
            print(f"   âœ… æ›´æ–°æ‰¿èª (Acc: {current_acc:.3f} -> {new_acc:.3f})")
            with self.predictor.model_lock:
                self.predictor.lgb_model = new_lgb_cls
                try:
                    import joblib
                    joblib.dump(new_lgb_cls, self.predictor.lgb_path)
                except: pass
        else:
            print(f"   ğŸ›‘ æ›´æ–°å´ä¸‹ (ç²¾åº¦ä½ä¸‹: {current_acc:.3f} -> {new_acc:.3f})")

        # ==========================================
        # 2. å›å¸°ãƒ¢ãƒ‡ãƒ« (LightGBM Regressor) ã®æ›´æ–°
        # ==========================================
        print("ğŸ“Š [2/3] å›å¸°ãƒ¢ãƒ‡ãƒ«(å€¤å¹…)ã®æ›´æ–°ãƒã‚§ãƒƒã‚¯")
        if 'future_change' in train_df.columns:
            y_reg_train = train_df['future_change']
            y_reg_val = val_df['future_change']
            
            # ç¾åœ¨ã®èª¤å·®(RMSE)ç¢ºèª
            current_rmse = 999.0
            with self.predictor.model_lock:
                if self.predictor.lgb_reg_model:
                    try:
                        preds = self.predictor.lgb_reg_model.predict(X_val)
                        current_rmse = np.sqrt(mean_squared_error(y_reg_val, preds))
                    except: pass
            
            # æ–°è¦å­¦ç¿’
            params_reg = {
                'objective': 'regression', 'metric': 'rmse', 'verbose': -1, 
                'random_state': 42, 'learning_rate': 0.05
            }
            train_set_reg = lgb.Dataset(X_train, label=y_reg_train)
            new_lgb_reg = lgb.train(params_reg, train_set_reg, num_boost_round=100)
            
            # æ–°è¦RMSEç¢ºèª
            new_preds = new_lgb_reg.predict(X_val)
            new_rmse = np.sqrt(mean_squared_error(y_reg_val, new_preds))
            
            # RMSEã¯ä½ã„æ–¹ãŒè‰¯ã„ (å¤šå°‘ã®æ‚ªåŒ–ã¯è¨±å®¹ã—ã¦æœ€æ–°ãƒˆãƒ¬ãƒ³ãƒ‰ã«è¿½å¾“ã•ã›ã‚‹)
            if new_rmse <= current_rmse * 1.1: 
                print(f"   âœ… æ›´æ–°æ‰¿èª (RMSE: {current_rmse:.4f} -> {new_rmse:.4f})")
                with self.predictor.model_lock:
                    self.predictor.lgb_reg_model = new_lgb_reg
                    try:
                        import joblib
                        joblib.dump(new_lgb_reg, self.predictor.lgb_reg_path)
                    except: pass
            else:
                print(f"   ğŸ›‘ æ›´æ–°å´ä¸‹ (èª¤å·®å¢—å¤§: {current_rmse:.4f} -> {new_rmse:.4f})")
        else:
            print("   âš ï¸ future_changeåˆ—ãŒãªã„ãŸã‚å›å¸°ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¹ã‚­ãƒƒãƒ—")

        # ==========================================
        # 3. LSTM å†å­¦ç¿’
        # ==========================================
        print("ğŸ§  [3/3] LSTMå†å­¦ç¿’ä¸­...")
        if 'close' in df.columns:
            prices = df['close'].values
            labels = df['label'].values
            self.predictor.train_lstm(prices, labels)

        self.last_retrain_time = time.time()
        print(f"âœ¨ å…¨ãƒ¢ãƒ‡ãƒ«æ›´æ–°ãƒ—ãƒ­ã‚»ã‚¹å®Œäº†")

    def start_background_learning(self):
        if self.is_running: return
        self.is_running = True
        self.learning_thread = threading.Thread(target=self._learning_loop, daemon=True)
        self.learning_thread.start()
        print(f"âœ… ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å­¦ç¿’é–‹å§‹")
    
    def _learning_loop(self):
        while self.is_running:
            elapsed = time.time() - self.last_retrain_time
            remaining = self.retrain_interval - elapsed
            
            if remaining <= 0:
                try:
                    self.retrain_models()
                except Exception as e:
                    print(f"âŒ å†å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
            
            sleep_time = min(3600, max(60, remaining))
            time.sleep(sleep_time)

    def stop_background_learning(self):
        self.is_running = False
        if self.learning_thread:
            self.learning_thread.join(timeout=5)