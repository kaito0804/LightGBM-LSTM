"""
ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  (ãƒ‡ã‚¤ãƒˆãƒ¬ãƒ¼ãƒ‰æœ€é©åŒ–ç‰ˆ)
- 15åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã®åé›†
- ãƒ¢ãƒ‡ãƒ«æ›´æ–°æ™‚ã®ç²¾åº¦ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½
"""

import pandas as pd
import os
import threading
import time
from datetime import datetime
from ml_predictor import MLPredictor
from data_collector import DataCollector
import lightgbm as lgb

class OnlineLearner:
    def __init__(self, symbol='ETH', timeframe='15m', retrain_interval_hours=24):
        self.symbol = symbol
        self.timeframe = timeframe # ãƒ‡ã‚¤ãƒˆãƒ¬ç”¨ã«15mãªã©ã‚’æŒ‡å®šå¯èƒ½
        self.retrain_interval = retrain_interval_hours * 3600
        
        self.collector = DataCollector(symbol)
        self.predictor = MLPredictor(symbol)
        
        self.training_data_path = f"training_data/{symbol}_{timeframe}_training.csv"
        self.last_retrain_time = time.time()
        self.max_rows = 40000
        
        self.learning_thread = None
        self.is_running = False
        
        print(f"ğŸ”„ ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’åˆæœŸåŒ–: {timeframe}è¶³ (é–“éš”: {retrain_interval_hours}h)")
    


    def collect_latest_data(self, lookback_limit=500):
        """
        æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¦CSVã«è¿½è¨˜
        """
        # æŒ‡å®šã•ã‚ŒãŸtimeframeã§åé›†
        new_df = self.collector.collect_historical_data(timeframe=self.timeframe, limit=lookback_limit)
        
        if new_df is None or new_df.empty:
            return None

        if os.path.exists(self.training_data_path):
            try:
                existing_df = pd.read_csv(self.training_data_path)
                combined_df = pd.concat([existing_df, new_df], ignore_index=True)
                if 'timestamp' in combined_df.columns:
                    combined_df = combined_df.drop_duplicates(subset=['timestamp'], keep='last')
                    combined_df = combined_df.sort_values('timestamp').reset_index(drop=True)
            except:
                combined_df = new_df
        else:
            combined_df = new_df

        if len(combined_df) > self.max_rows:
            combined_df = combined_df.tail(self.max_rows)

        os.makedirs(os.path.dirname(self.training_data_path), exist_ok=True)
        combined_df.to_csv(self.training_data_path, index=False)
        
        return combined_df


    
    def retrain_models(self):
        """
        å®‰å…¨è£…ç½®ä»˜ãå†å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹
        """
        # 1. æœ€æ–°ãƒ‡ãƒ¼ã‚¿åé›†
        df = self.collect_latest_data(lookback_limit=200)
        if df is None or len(df) < 500:
            print("âš ï¸ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
            return

        print(f"ğŸ”„ å®‰å…¨å†å­¦ç¿’é–‹å§‹: {len(df)} lines")
        
        # 2. ç›´è¿‘ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼ç”¨(Validation)ã«å–ã‚Šåˆ†ã‘ã‚‹ (æœ€æ–°15%)
        split_idx = int(len(df) * 0.85)
        train_df = df.iloc[:split_idx]
        val_df = df.iloc[split_idx:]
        
        feature_cols = self.predictor.feature_cols
        
        # ç‰¹å¾´é‡ã®æ¬ æåŸ‹ã‚
        for c in feature_cols:
            if c not in train_df.columns: train_df[c] = 0
            if c not in val_df.columns: val_df[c] = 0

        X_val = val_df[feature_cols]
        y_val = val_df['label']
        
        # === LightGBM å®‰å…¨æ›´æ–° ===
        # ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’ç¢ºèª
        current_acc = 0.0
        with self.predictor.model_lock:
            if self.predictor.lgb_model:
                current_acc = self.predictor.evaluate_model(self.predictor.lgb_model, X_val, y_val, 'lgb')
        
        print(f"   ç¾åœ¨ã®LGBMç²¾åº¦: {current_acc:.4f}")

        # æ–°è¦ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
        X_train = train_df[feature_cols]
        y_train = train_df['label']
        y_train_mapped = y_train.map({-1:0, 0:1, 1:2})
        
        params = {
            'objective': 'multiclass', 'num_class': 3, 'verbose': -1, 
            'random_state': 42, 'learning_rate': 0.05
        }
        train_set = lgb.Dataset(X_train, label=y_train_mapped)
        new_lgb = lgb.train(params, train_set, num_boost_round=100)
        
        # æ–°è¦ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
        new_acc = self.predictor.evaluate_model(new_lgb, X_val, y_val, 'lgb')
        print(f"   æ–°è¦LGBMç²¾åº¦: {new_acc:.4f}")
        
        # æ›´æ–°åˆ¤å®š (ç²¾åº¦ãŒæ‚ªåŒ–ã—ã¦ã„ãªã‘ã‚Œã°æ¡ç”¨)
        if new_acc >= current_acc - 0.03: # å¤šå°‘ã®ãƒ–ãƒ¬ã¯è¨±å®¹
            print("âœ¨ LGBMæ›´æ–°æ‰¿èª")
            with self.predictor.model_lock:
                self.predictor.lgb_model = new_lgb
                try:
                    import joblib
                    joblib.dump(new_lgb, self.predictor.lgb_path)
                except: pass
        else:
            print("ğŸ›‘ LGBMæ›´æ–°å´ä¸‹: ç²¾åº¦åŠ£åŒ–")

        # === LSTM å†å­¦ç¿’ (å¸¸æ™‚æ›´æ–°) ===
        # LSTMã¯æ§‹é€ ä¸Šã€ç¶™ç¶šå­¦ç¿’ã«è¿‘ã„å½¢ã‚’ã¨ã‚‹ãŸã‚ã“ã“ã§ã¯ãã®ã¾ã¾æ›´æ–°
        print("ğŸ§  LSTMå†å­¦ç¿’ä¸­...")
        if 'close' in df.columns:
            prices = df['close'].values
            labels = df['label'].values
            self.predictor.train_lstm(prices, labels)

        self.last_retrain_time = time.time()
        print(f"âœ¨ ãƒ¢ãƒ‡ãƒ«æ›´æ–°ãƒ—ãƒ­ã‚»ã‚¹å®Œäº†")
    


    def start_background_learning(self):
        if self.is_running: return
        self.is_running = True
        self.learning_thread = threading.Thread(target=self._learning_loop, daemon=True)
        self.learning_thread.start()
        print(f"âœ… ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å­¦ç¿’é–‹å§‹")


    
    def _learning_loop(self):
        while self.is_running:
            elapsed = time.time() - self.last_retrain_time
            remaining = self.retrain_interval - elapsed
            
            if remaining <= 0:
                try:
                    self.retrain_models()
                except Exception as e:
                    print(f"âŒ å†å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
            
            sleep_time = min(3600, max(60, remaining))
            time.sleep(sleep_time)

            

    def stop_background_learning(self):
        self.is_running = False
        if self.learning_thread:
            self.learning_thread.join(timeout=5)