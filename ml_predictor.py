"""
æ©Ÿæ¢°å­¦ç¿’ãƒ™ãƒ¼ã‚¹ã®ä¾¡æ ¼äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  (ãƒ‡ã‚¤ãƒˆãƒ¬ãƒ¼ãƒ‰æœ€é©åŒ–ç‰ˆ)
- LightGBM: ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿äºˆæ¸¬ (æ¿æƒ…å ±è¿½åŠ )
- LSTM: å¯¾æ•°å¤‰åŒ–ç‡ã‚’ä½¿ç”¨ã—ãŸæ™‚ç³»åˆ—äºˆæ¸¬
- è©•ä¾¡æ©Ÿèƒ½: ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã®å®‰å…¨æ€§ç¢ºä¿
"""
import numpy as np
import pandas as pd
import joblib
import os
import threading

try:
    from sklearn.metrics import accuracy_score
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    print("âš ï¸ scikit-learnãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚'pip install scikit-learn' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False

try:
    from tensorflow import keras
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import LSTM, Dense, Dropout
    KERAS_AVAILABLE = True
except ImportError:
    KERAS_AVAILABLE = False

class MLPredictor:
    def __init__(self, symbol='ETH', model_dir='models'):
        self.symbol = symbol
        self.model_dir = model_dir
        os.makedirs(model_dir, exist_ok=True)
        self.lgb_path = f"{model_dir}/lgb_{symbol}.pkl"
        self.lstm_path = f"{model_dir}/lstm_{symbol}.h5"
        
        self.model_lock = threading.Lock()
        
        self.lgb_model = None
        self.lstm_model = None
        
        # ç‰¹å¾´é‡å®šç¾© (Imbalanceã‚’è¿½åŠ )
        self.feature_cols = [
            'orderbook_imbalance',  
            'btc_correlation',      
            'btc_trend_strength',
            'rsi', 'macd_hist', 'bb_position', 'bb_width',
            'atr', 'volume_ratio', 'price_change_1h',
            'price_change_4h', 'sma_20_50_ratio', 'volatility',
            'hour_sin', 'hour_cos', 'day_of_week'
        ]
        self.lstm_lookback = 60
        self.load_models()

    def create_features_from_history(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å¾´é‡ã‚’è¨ˆç®— (æ¨è«–ç”¨)
        """
        df = df.copy()
        if len(df) < 100:
            return None

        # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™è¨ˆç®—
        close = df['close']
        
        # RSI
        delta = close.diff()
        gain = (delta.where(delta > 0, 0)).ewm(alpha=1/14, adjust=False).mean()
        loss = (-delta.where(delta < 0, 0)).ewm(alpha=1/14, adjust=False).mean()
        rs = gain / loss.replace(0, np.nan)
        df['rsi'] = 100 - (100 / (1 + rs))
        df['rsi'] = df['rsi'].fillna(50)
        
        # MACD
        ema12 = close.ewm(span=12, adjust=False).mean()
        ema26 = close.ewm(span=26, adjust=False).mean()
        macd = ema12 - ema26
        signal = macd.ewm(span=9, adjust=False).mean()
        df['macd_hist'] = macd - signal
        
        # BB
        sma20 = close.rolling(20).mean()
        std20 = close.rolling(20).std(ddof=0)
        df['bb_position'] = (close - (sma20 - 2*std20)) / (4*std20)
        df['bb_width'] = (4*std20) / sma20
        
        # SMA Ratio
        sma50 = close.rolling(50).mean()
        df['sma_20_50_ratio'] = (sma20 / sma50 - 1) * 100
        
        # Volume
        vol_ma = df['volume'].rolling(20).mean()
        df['volume_ratio'] = df['volume'] / vol_ma.replace(0, 1)
        
        # Price Change
        df['price_change_1h'] = close.pct_change(1) * 100
        df['price_change_4h'] = close.pct_change(4) * 100
        
        # Volatility
        df['volatility'] = close.rolling(20).std() / sma20 * 100
        
        # ATR
        tr1 = df['high'] - df['low']
        tr2 = (df['high'] - df['close'].shift()).abs()
        tr3 = (df['low'] - df['close'].shift()).abs()
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        df['atr'] = tr.ewm(alpha=1/14, adjust=False).mean()

        # Time Features
        if 'timestamp' in df.columns:
            dates = pd.to_datetime(df['timestamp'])
        else:
            dates = df.index
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å‹ã«å¿œã˜ãŸå‡¦ç†
        if hasattr(dates, 'hour'):
            hours = dates.hour
            dayofweek = dates.dayofweek
        elif hasattr(dates, 'dt'):
            hours = dates.dt.hour
            dayofweek = dates.dt.dayofweek
        else:
            hours = pd.Series(0, index=df.index)
            dayofweek = pd.Series(0, index=df.index)

        df['hour_sin'] = np.sin(2 * np.pi * hours / 24)
        df['hour_cos'] = np.cos(2 * np.pi * hours / 24)
        df['day_of_week'] = dayofweek / 6.0

        available_cols  = [c for c in self.feature_cols if c in df.columns]
        latest_features = df.iloc[[-1]][available_cols].fillna(0)
        
        return latest_features

    def prepare_lstm_data(self, prices: np.ndarray) -> np.ndarray:
        """
        LSTMç”¨ãƒ‡ãƒ¼ã‚¿ä½œæˆ (å¯¾æ•°å¤‰åŒ–ç‡ + æ­£è¦åŒ–)
        """
        if len(prices) < self.lstm_lookback + 1:
            return np.zeros((1, self.lstm_lookback, 1))
        
        # ä¾¡æ ¼ãã®ã‚‚ã®ã§ã¯ãªãã€å¤‰åŒ–ç‡ã‚’ä½¿ã†ï¼ˆä¾¡æ ¼æ°´æº–ãŒå¤‰ã‚ã£ã¦ã‚‚å¯¾å¿œå¯èƒ½ã«ï¼‰
        s = pd.Series(prices)
        returns = np.log(s / s.shift(1)).fillna(0).values
        
        window = returns[-self.lstm_lookback:]
        
        # Z-scoreæ­£è¦åŒ–
        mean = window.mean()
        std = window.std() + 1e-8
        normalized = (window - mean) / std
            
        return normalized.reshape(1, self.lstm_lookback, 1)

    # ---------------------------------------------------------
# MLPredictorã‚¯ãƒ©ã‚¹å†…ã® predict é–¢æ•°ã‚’ä¸¸ã”ã¨ã“ã‚Œã«ç½®ãæ›ãˆã¦ãã ã•ã„
# ---------------------------------------------------------
    def predict(self, df: pd.DataFrame, extra_features: dict = None) -> dict:
        """
        äºˆæ¸¬å®Ÿè¡Œ (åŸ·è¡Œãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä»˜ã)
        """
        if df is None or len(df) < 100:
            return {'action': 'HOLD', 'confidence': 0, 'reasoning': 'ãƒ‡ãƒ¼ã‚¿ä¸è¶³', 'model_used': 'NONE'}

        # 1. ç‰¹å¾´é‡ä½œæˆ
        features = self.create_features_from_history(df)

        if features is None:
            return {'action': 'HOLD', 'confidence': 0, 'model_used': 'NONE'}
        
        # 2. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã®æ³¨å…¥
        if extra_features:
            features['orderbook_imbalance'] = extra_features.get('orderbook_imbalance', 0.0)
            features['btc_correlation'] = extra_features.get('btc_trend', 0.0) 
            features['btc_trend_strength'] = abs(extra_features.get('btc_trend', 0.0))
        else:
            print("âš ï¸ è­¦å‘Š: æ¿æƒ…å ±ãƒ»BTCãƒ‡ãƒ¼ã‚¿ãŒæ¬ è½ã—ã¦ã„ã¾ã™ã€‚ç²¾åº¦ãŒä½ä¸‹ã—ã¾ã™ã€‚")
            features['orderbook_imbalance'] = 0.0
            features['btc_correlation'] = 0.0
            features['btc_trend_strength'] = 0.0
        
        # ã‚«ãƒ©ãƒ é †åºã®ä¿è¨¼ã¨æ¬ æåŸ‹ã‚
        for col in self.feature_cols:
            if col not in features.columns:
                features[col] = 0.0
        features = features[self.feature_cols]

        with self.model_lock:
            lgb_model = self.lgb_model
            lstm_model = self.lstm_model

        # 3. LightGBM äºˆæ¸¬
        lgb_up = 0.0
        lgb_down = 0.0
        lgb_used = False
        
        if lgb_model:
            try:
                lgb_pred = lgb_model.predict(features)
                lgb_down = float(lgb_pred[0][0])
                lgb_up = float(lgb_pred[0][2])
                lgb_used = True
            except Exception as e:
                print(f"âš ï¸ LGBMäºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")

        # 4. LSTM äºˆæ¸¬
        lstm_up = 0.0
        lstm_down = 0.0
        lstm_used = False
        
        if lstm_model:
            try:
                prices = df['close'].values
                inp = self.prepare_lstm_data(prices)
                lstm_pred = lstm_model.predict(inp, verbose=0)[0]
                lstm_down = float(lstm_pred[0])
                lstm_up = float(lstm_pred[2])
                lstm_used = True
            except Exception as e:
                print(f"âš ï¸ LSTMäºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")

        # 5. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« (ç¢ºç‡ã®çµ±åˆ)
        if lgb_used and lstm_used:
            final_up = (lgb_up * 0.6 + lstm_up * 0.4)
            final_down = (lgb_down * 0.6 + lstm_down * 0.4)
            model_name = "Ensemble"
        elif lgb_used:
            final_up = lgb_up
            final_down = lgb_down
            model_name = "LightGBM"
        elif lstm_used:
            final_up = lstm_up
            final_down = lstm_down
            model_name = "LSTM"
        else:
            return {'action': 'HOLD', 'confidence': 0, 'reasoning': 'ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬å¤±æ•—', 'model_used': 'NONE'}

        # ---------------------------------------------------------
        # AIãŒGOã‚µã‚¤ãƒ³ã‚’å‡ºã—ã¦ã‚‚ã€æ¿æƒ…å ±ã‚„BTCçŠ¶æ³ãŒæ‚ªã‘ã‚Œã°æ‹’å¦ã™ã‚‹
        # ---------------------------------------------------------
        filter_reason = ""
        is_filtered = False

        # æ¿æƒ…å ± (Imbalance) ã®ãƒã‚§ãƒƒã‚¯
        # å€¤ãŒæ­£ãªã‚‰è²·ã„åœ§ã€è² ãªã‚‰å£²ã‚Šåœ§
        imbalance = features['orderbook_imbalance'].iloc[-1]
        
        if final_up > final_down: # AIåˆ¤æ–­: BUY
            # å£²ã‚Šæ¿ãŒæ¥µç«¯ã«åšã„å ´åˆ (-0.3ä»¥ä¸‹) ã¯ã‚­ãƒ£ãƒ³ã‚»ãƒ«
            if imbalance < -0.3:
                is_filtered = True
                filter_reason = f"å£²ã‚Šæ¿åšéå¤š(Imb:{imbalance:.2f})"
                final_up = 0.0 # å¼·åˆ¶ãƒªã‚»ãƒƒãƒˆ
        
        elif final_down > final_up: # AIåˆ¤æ–­: SELL
            # è²·ã„æ¿ãŒæ¥µç«¯ã«åšã„å ´åˆ (0.3ä»¥ä¸Š) ã¯ã‚­ãƒ£ãƒ³ã‚»ãƒ«
            if imbalance > 0.3:
                is_filtered = True
                filter_reason = f"è²·ã„æ¿åšéå¤š(Imb:{imbalance:.2f})"
                final_down = 0.0 # å¼·åˆ¶ãƒªã‚»ãƒƒãƒˆ

        # BTCç›¸é–¢ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        # BTCãŒæ€¥è½ä¸­ (-0.5%ä»¥ä¸‹) ã«ETHã®è²·ã„ã‚’å…¥ã‚Œã‚‹ã®ã¯å±é™º
        btc_trend = features['btc_correlation'].iloc[-1]
        if final_up > final_down and btc_trend < -0.5:
             is_filtered = True
             filter_reason = f"BTCæ€¥è½ä¸­({btc_trend:.2f}%)"
             final_up = 0.0

        if is_filtered:
            print(f"ğŸ›¡ï¸ åŸ·è¡Œãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç™ºå‹•: {filter_reason} -> ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«")

        # è‡ªä¿¡åº¦è¨ˆç®—
        max_prob = max(final_up, final_down)
        
        # é–¾å€¤ (0.4ä»¥ä¸Šã§åå¿œ)
        if max_prob < 0.4:
            confidence = 0
        else:
            confidence = (max_prob - 0.4) / (0.9 - 0.4) * 100
            confidence = min(100, max(0, confidence))

        return {
            'action': 'PREDICTED',
            'up_prob': final_up,
            'down_prob': final_down,
            'confidence': int(confidence),
            'model_used': model_name,
            'reasoning': f"Up:{final_up:.2f} Down:{final_down:.2f} {filter_reason}"
        }

    def evaluate_model(self, model, X_val, y_val, model_type='lgb'):
        """
        ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦è©•ä¾¡ (ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ç”¨)
        """
        if not SKLEARN_AVAILABLE: return 0.0
        try:
            if len(X_val) == 0: return 0.0
            
            if model_type == 'lgb':
                preds = model.predict(X_val)
                pred_classes = np.argmax(preds, axis=1)
                # ãƒ©ãƒ™ãƒ«ãƒãƒƒãƒ—: -1->0, 0->1, 1->2
                y_true = y_val.map({-1:0, 0:1, 1:2}).fillna(1)
                return accuracy_score(y_true, pred_classes)
            
            return 0.0
        except Exception as e:
            print(f"è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0

    def train_lightgbm(self, X, y, X_val=None, y_val=None):
        if not LIGHTGBM_AVAILABLE: return
        
        # å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (ãƒ‡ã‚¤ãƒˆãƒ¬ç”¨: ã‚„ã‚„éå­¦ç¿’ã‚’é˜²ãè¨­å®š)
        params = {
            'objective': 'multiclass', 
            'num_class': 3, 
            'metric': 'multi_logloss', 
            'verbose': -1, 
            'random_state': 42,
            'learning_rate': 0.05,
            'num_leaves': 31
        }
        y_mapped = y.map({-1:0, 0:1, 1:2})
        train_data = lgb.Dataset(X, label=y_mapped)
        valid_sets = []
        if X_val is not None:
            y_val_mapped = y_val.map({-1:0, 0:1, 1:2})
            valid_sets = [lgb.Dataset(X_val, label=y_val_mapped, reference=train_data)]
        
        new_model = lgb.train(params, train_data, num_boost_round=100, valid_sets=valid_sets)
        
        with self.model_lock:
            self.lgb_model = new_model
            joblib.dump(self.lgb_model, self.lgb_path)
    
    def train_lstm(self, prices, labels, lookback=60, epochs=20):
        if not KERAS_AVAILABLE: return
        
        # ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        X, y = [], []
        s = pd.Series(prices)
        # å¯¾æ•°å¤‰åŒ–ç‡
        returns = np.log(s / s.shift(1)).fillna(0).values
        
        for i in range(lookback, len(returns)):
            window = returns[i-lookback:i]
            mean = window.mean()
            std = window.std() + 1e-8
            norm = (window - mean) / std
            
            X.append(norm)
            l = labels[i]
            if l == -1: enc = [1,0,0]
            elif l == 0: enc = [0,1,0]
            else: enc = [0,0,1]
            y.append(enc)
            
        if len(X) == 0: return

        X = np.array(X).reshape(-1, lookback, 1)
        y = np.array(y)
        
        model = Sequential([
            LSTM(64, return_sequences=True, input_shape=(lookback, 1)), Dropout(0.2),
            LSTM(32), Dropout(0.2), Dense(3, activation='softmax')
        ])
        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
        model.fit(X, y, epochs=epochs, batch_size=32, validation_split=0.2, verbose=1)
        
        with self.model_lock:
            self.lstm_model = model
            model.save(self.lstm_path)

    def load_models(self):
        if os.path.exists(self.lgb_path) and LIGHTGBM_AVAILABLE:
            try: self.lgb_model = joblib.load(self.lgb_path)
            except Exception as e: print(f"âš ï¸ LGBMèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

        if os.path.exists(self.lstm_path) and KERAS_AVAILABLE:
            try: self.lstm_model = keras.models.load_model(self.lstm_path)
            except Exception as e: print(f"âš ï¸ LSTMèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")